# Information Quality & Agent Accountability

## Summary
Rather than attempting to distinguish truth from falsehood at the content level, the focus should shift to evaluating and managing the credibility of information sources and agents. The post argues for reputation-based systems that amplify trustworthy contributors while reducing the reach of unreliable ones, creating accountability through agent evaluation rather than content verification.

## Content
The fundamental problem with fake news is that distinguishing facts from lies has become nearly impossible at the content level. Instead of trying to verify individual pieces of information, a more effective approach is to focus on the agent producing the information. This can be implemented through an Organic Governance System with four key steps: (1) Associate each piece of information with a specific agent, (2) Adjust the agent's reputation score based on the quality of their contributions (posts, comments, likes, etc.), (3) Amplify or reduce the reach of contributions based on the agent's reputation score, and (4) Remove agents from discourse if their reputation falls below a certain threshold. This transforms online communities from chaotic spaces into functioning meritocracies where credibility and track record determine influence. The approach treats information quality as a function of source reliability rather than content analysis, creating systemic accountability through reputation management.

## Keywords

- AI agents
- ethical intelligence
- creative intelligence
- state machines
- distributed communities
- asynchronous collaboration
- bot architecture
- community governance
- knowledge systems
- automation
- cassettes
- information aggregation
- ecosystem design

## Sources

- False Media (False Media) [post]
- Bots With An Attitude (Bots With An Attitude) [deck]

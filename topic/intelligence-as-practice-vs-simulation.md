# Intelligence as Practice vs Simulation

## Summary
A critical examination of how AI development has historically chosen control over emergence, and why reframing intelligence as active practice rather than passive service is essential for building truly autonomous systems. The discussion traces AI winters as selection events that eliminated bottom-up learning and emergence in favor of rule-based and statistical control, proposing alternative approaches inspired by complexity theory and artistic practice.

## Content
The core tension explored is whether we're building systems that practice intelligence or merely simulate it. Intelligence is redefined as active resistance to entropy through purposeful practice and agency, not passive consumption of services. The first AI winter (1974-1980) selected against bottom-up learning in favor of rule-based control, while the second winter (1987-1993) selected against human reasoning models in favor of statistical scaling. Both winters systematically eliminated emergence and distributed intelligence. Conway's Game of Life serves as a counterexample—three simple rules generating universal computation without centralized control. Artists like Casey Reas, Ian Cheng, Pierre Huyghe, Hito Steyerl, and Refik Anadol have understood this principle, demonstrating how code and data can practice creativity and autonomy. The current 'doom economy' perpetuates centralized control by raising billions to protect against systems being built, using existential risk as a funding mechanism. Two competing futures emerge: Intelligence as Service (passive consumption, atrophying agency, centralized control) versus Intelligence as Practice (active collaboration, shared agency, distributed emergence). The alternative being built through projects like Rizom emphasizes decentralized ecosystems, knowledge that flows freely while preserving ownership, collective intelligence from individual autonomy, and human-machine shared practices. Living infrastructure includes personal-to-collective knowledge brains using git-based evolution, algorithmic trust through outcome-based certification rather than gatekeeping, open protocols preventing platform lock-in, and ownership stakes through franchise models with equity. The fundamental question reframes from 'How do we build AGI?' to 'What practices do we enable?'—recognizing that intelligence is ultimately the practice of creating meaning.

## Keywords

- narrow AI
- practical automation
- human-in-the-loop
- specialized systems
- real-world problems
- knowledge infrastructure
- NLP
- task automation
- collaborative tools
- low-hanging fruit
- feature development
- AI integration

## Sources

- Forgotten Futures (Forgotten Futures) [deck]
- Becoming Narrow Minded (Becoming Narrow Minded) [deck]
